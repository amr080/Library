<h1>DOWNLOADING WEBSITES FOR DUMMIES<h1>
<p>the internet is a highway for packets of information</p>  

  
<h3>Dependencies</h3>
<ul>
  <li>Linux</li>
  <li>ubuntu terminal</li>
</ul>

<pre>wget -r -k -E -l 10 -p -np -w 1 -e robots=off &lt;URL&gt;</pre>
<ul>
  <li><strong>-r</strong>: Recursively download</li>
  <li><strong>-k</strong>: Convert links for offline use</li>
  <li><strong>-E</strong>: Save HTML files with proper extensions</li>
  <li><strong>-l 10</strong>: Limit recursion depth to 10 levels</li>
  <li><strong>-p</strong>: Download all necessary files for full page display</li>
  <li><strong>-np</strong>: Don't ascend to parent directories</li>
  <li><strong>-w 1</strong>: Wait 1 second between downloads</li>
  <li><strong>-e robots=off</strong>: Ignore <code>robots.txt</code> restrictions</li>
  <li><strong>&lt;URL&gt;</strong>: Target URL for download</li>
</ul>



<pre>wget -r -np -k -p --domains=jpmorgan.com -I /kinexys/ https://www.jpmorgan.com/kinexys/</pre>
  
